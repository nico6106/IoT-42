
reussite sur worker

Feb 14 09:16:59 nlesageSW systemd[1]: Stopped k3s-agent.service - Lightweight Kubernetes.
Feb 14 09:16:59 nlesageSW systemd[1]: k3s-agent.service: Consumed 6.453s CPU time.
Feb 14 09:17:48 nlesageSW systemd[1]: Starting k3s-agent.service - Lightweight Kubernetes...
Feb 14 09:17:48 nlesageSW sh[3911]: + /usr/bin/systemctl is-enabled --quiet nm-cloud-setup.service
Feb 14 09:17:49 nlesageSW k3s[3916]: time="2024-02-14T09:17:49Z" level=info msg="Acquiring lock file /var/lib/rancher/k3s/data/.lock"
Feb 14 09:17:49 nlesageSW k3s[3916]: time="2024-02-14T09:17:49Z" level=info msg="Preparing data dir /var/lib/rancher/k3s/data/13f9723ffde84ba41d08658d407a523bcf32698f179c9ab30cc0534e1e5d2c1a"
Feb 14 09:17:55 nlesageSW k3s[3916]: time="2024-02-14T09:17:55Z" level=info msg="Starting k3s agent v1.28.6+k3s2 (c9f49a3b)"
Feb 14 09:17:55 nlesageSW k3s[3916]: time="2024-02-14T09:17:55Z" level=info msg="Adding server to load balancer k3s-agent-load-balancer: 192.168.56.110:6443"
Feb 14 09:17:55 nlesageSW k3s[3916]: time="2024-02-14T09:17:55Z" level=info msg="Running load balancer k3s-agent-load-balancer 127.0.0.1:6444 -> [192.168.56.110:6443] [default: 192.168.56.110:6443]"
Feb 14 09:18:51 nlesageSW k3s[3916]: time="2024-02-14T09:18:51Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Get \"https://127.0.0.1:6444/v1-k3s/client-kubelet.crt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
Feb 14 09:19:19 nlesageSW k3s[3916]: time="2024-02-14T09:19:19Z" level=info msg="Module overlay was already loaded"
Feb 14 09:19:19 nlesageSW k3s[3916]: time="2024-02-14T09:19:19Z" level=info msg="Module br_netfilter was already loaded"
Feb 14 09:19:20 nlesageSW k3s[3916]: time="2024-02-14T09:19:20Z" level=info msg="Set sysctl 'net/ipv4/conf/all/forwarding' to 1"
Feb 14 09:19:20 nlesageSW k3s[3916]: time="2024-02-14T09:19:20Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_max' to 131072"
Feb 14 09:19:20 nlesageSW k3s[3916]: time="2024-02-14T09:19:20Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400"
Feb 14 09:19:20 nlesageSW k3s[3916]: time="2024-02-14T09:19:20Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600"
Feb 14 09:19:20 nlesageSW k3s[3916]: time="2024-02-14T09:19:20Z" level=info msg="Logging containerd to /var/lib/rancher/k3s/agent/containerd/containerd.log"
Feb 14 09:19:20 nlesageSW k3s[3916]: time="2024-02-14T09:19:20Z" level=info msg="Running containerd -c /var/lib/rancher/k3s/agent/etc/containerd/config.toml -a /run/k3s/containerd/containerd.sock --state /run/k3s/containerd --root /var/lib/rancher/k3s/agent/containerd"
Feb 14 09:19:21 nlesageSW k3s[3916]: time="2024-02-14T09:19:21Z" level=info msg="Waiting for containerd startup: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing: dial unix /run/k3s/containerd/containerd.sock: connect: no such file or directory\""
Feb 14 09:19:22 nlesageSW k3s[3916]: time="2024-02-14T09:19:22Z" level=info msg="containerd is now running"
Feb 14 09:19:22 nlesageSW k3s[3916]: time="2024-02-14T09:19:22Z" level=info msg="Getting list of apiserver endpoints from server"
Feb 14 09:19:33 nlesageSW k3s[3916]: time="2024-02-14T09:19:33Z" level=info msg="Updated load balancer k3s-agent-load-balancer default server address -> 192.168.56.110:6443"
Feb 14 09:19:33 nlesageSW k3s[3916]: time="2024-02-14T09:19:33Z" level=info msg="Running kubelet --address=0.0.0.0 --allowed-unsafe-sysctls=net.ipv4.ip_forward,net.ipv6.conf.all.forwarding --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/k3s/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available<5%,nodefs.available<5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=nlesagesw --kubeconfig=/var/lib/rancher/k3s/agent/kubelet.kubeconfig --node-ip=10.0.2.15 --node-labels= --pod-infra-container-image=rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/k3s/agent/pod-manifests --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/k3s/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/k3s/agent/serving-kubelet.key"
Feb 14 09:19:33 nlesageSW k3s[3916]: time="2024-02-14T09:19:33Z" level=info msg="Connecting to proxy" url="wss://192.168.56.110:6443/v1-k3s/connect"
Feb 14 09:19:43 nlesageSW k3s[3916]: time="2024-02-14T09:19:43Z" level=info msg="Running kube-proxy --cluster-cidr=10.42.0.0/16 --conntrack-max-per-core=0 --conntrack-tcp-timeout-close-wait=0s --conntrack-tcp-timeout-established=0s --healthz-bind-address=127.0.0.1 --hostname-override=nlesagesw --kubeconfig=/var/lib/rancher/k3s/agent/kubeproxy.kubeconfig --proxy-mode=iptables"
Feb 14 09:19:50 nlesageSW k3s[3916]: E0214 09:19:50.453938    3916 node.go:130] Failed to retrieve node info: nodes "nlesagesw" not found
Feb 14 09:20:03 nlesageSW k3s[3916]: E0214 09:20:03.711773    3916 node.go:130] Failed to retrieve node info: nodes "nlesagesw" not found
Feb 14 09:20:12 nlesageSW k3s[3916]: E0214 09:20:12.028248    3916 node.go:130] Failed to retrieve node info: nodes "nlesagesw" not found
Feb 14 09:20:27 nlesageSW k3s[3916]: E0214 09:20:27.997244    3916 node.go:130] Failed to retrieve node info: nodes "nlesagesw" not found
Feb 14 09:20:41 nlesageSW k3s[3916]: E0214 09:20:41.217545    3916 node.go:130] Failed to retrieve node info: nodes "nlesagesw" not found
Feb 14 09:20:42 nlesageSW k3s[3916]: Flag --cloud-provider has been deprecated, will be removed in 1.25 or later, in favor of removing cloud provider code from Kubelet.
Feb 14 09:20:42 nlesageSW k3s[3916]: Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
Feb 14 09:20:42 nlesageSW k3s[3916]: Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.039634    3916 server.go:202] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.061363    3916 server.go:462] "Kubelet version" kubeletVersion="v1.28.6+k3s2"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.062408    3916 server.go:464] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.073352    3916 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/agent/client-ca.crt"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.127060    3916 server.go:720] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.132328    3916 container_manager_linux.go:265] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.133722    3916 container_manager_linux.go:270] "Creating Container Manager object based on Node Config" nodeConfig={"RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"systemd","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"imagefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null}
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.135606    3916 topology_manager.go:138] "Creating topology manager with none policy"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.136522    3916 container_manager_linux.go:301] "Creating device plugin manager"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.138361    3916 state_mem.go:36] "Initialized new in-memory state store"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.141416    3916 kubelet.go:393] "Attempting to sync node with API server"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.142357    3916 kubelet.go:298] "Adding static pod path" path="/var/lib/rancher/k3s/agent/pod-manifests"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.143580    3916 kubelet.go:309] "Adding apiserver pod source"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.144608    3916 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.152213    3916 kuberuntime_manager.go:257] "Container runtime initialized" containerRuntime="containerd" version="v1.7.11-k3s2" apiVersion="v1"
Feb 14 09:20:42 nlesageSW k3s[3916]: W0214 09:20:42.225678    3916 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.280653    3916 server.go:1227] "Started kubelet"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.289015    3916 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.291800    3916 server.go:162] "Starting to listen" address="0.0.0.0" port=10250
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.295051    3916 server.go:462] "Adding debug handlers to kubelet server"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.298993    3916 ratelimit.go:65] "Setting rate limiting for podresources endpoint" qps=100 burstTokens=10
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.422793    3916 server.go:233] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.412591    3916 volume_manager.go:291] "Starting Kubelet Volume Manager"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.412602    3916 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.428527    3916 reconciler_new.go:29] "Reconciler: start to sync state"
Feb 14 09:20:42 nlesageSW k3s[3916]: E0214 09:20:42.460179    3916 cri_stats_provider.go:448] "Failed to get the info of the filesystem with mountpoint" err="unable to find data in memory cache" mountpoint="/var/lib/rancher/k3s/agent/containerd/io.containerd.snapshotter.v1.overlayfs"
Feb 14 09:20:42 nlesageSW k3s[3916]: E0214 09:20:42.461865    3916 kubelet.go:1431] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
Feb 14 09:20:42 nlesageSW k3s[3916]: E0214 09:20:42.539079    3916 container_manager_linux.go:881] "Unable to get rootfs data from cAdvisor interface" err="unable to find data in memory cache"
Feb 14 09:20:42 nlesageSW k3s[3916]: I0214 09:20:42.628467    3916 kubelet_node_status.go:70] "Attempting to register node" node="nlesagesw"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.362957    3916 cpu_manager.go:214] "Starting CPU manager" policy="none"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.368267    3916 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.368367    3916 state_mem.go:36] "Initialized new in-memory state store"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.374270    3916 policy_none.go:49] "None policy: Start"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.378131    3916 memory_manager.go:169] "Starting memorymanager" policy="None"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.378946    3916 state_mem.go:35] "Initializing new in-memory state store"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.560158    3916 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.622622    3916 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.624138    3916 status_manager.go:217] "Starting to sync pod status with apiserver"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.625286    3916 kubelet.go:2303] "Starting kubelet main sync loop"
Feb 14 09:20:43 nlesageSW k3s[3916]: E0214 09:20:43.627217    3916 kubelet.go:2327] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Feb 14 09:20:43 nlesageSW k3s[3916]: E0214 09:20:43.749026    3916 kubelet.go:2327] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.929912    3916 manager.go:471] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Feb 14 09:20:43 nlesageSW k3s[3916]: I0214 09:20:43.949941    3916 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Feb 14 09:20:43 nlesageSW k3s[3916]: E0214 09:20:43.953417    3916 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"nlesagesw\" not found"
Feb 14 09:20:46 nlesageSW k3s[3916]: I0214 09:20:46.329789    3916 apiserver.go:52] "Watching apiserver"
Feb 14 09:20:48 nlesageSW k3s[3916]: I0214 09:20:48.128214    3916 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
Feb 14 09:20:48 nlesageSW k3s[3916]: I0214 09:20:48.941049    3916 kubelet_node_status.go:73] "Successfully registered node" node="nlesagesw"
Feb 14 09:21:02 nlesageSW k3s[3916]: W0214 09:21:02.692715    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:21:02 nlesageSW k3s[3916]: E0214 09:21:02.697688    3916 controller.go:146] "Failed to ensure lease exists, will retry" err="Post \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="200ms"
Feb 14 09:21:12 nlesageSW k3s[3916]: W0214 09:21:12.898822    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:21:12 nlesageSW k3s[3916]: E0214 09:21:12.902740    3916 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/nlesagesw?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="400ms"
Feb 14 09:21:14 nlesageSW k3s[3916]: time="2024-02-14T09:21:14Z" level=info msg="Failed to set annotations and labels on node nlesagesw: Operation cannot be fulfilled on nodes \"nlesagesw\": the object has been modified; please apply your changes to the latest version and try again"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.602171    3916 node.go:141] Successfully retrieved node IP: 10.0.2.15
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.749330    3916 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.806533    3916 server_others.go:152] "Using iptables Proxier"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.807681    3916 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.808788    3916 server_others.go:438] "Defaulting to no-op detect-local"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.810310    3916 proxier.go:251] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.814251    3916 server.go:846] "Version info" version="v1.28.6+k3s2"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.815669    3916 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.936606    3916 config.go:188] "Starting service config controller"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.938391    3916 shared_informer.go:311] Waiting for caches to sync for service config
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.939354    3916 config.go:97] "Starting endpoint slice config controller"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.940163    3916 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.944741    3916 config.go:315] "Starting node config controller"
Feb 14 09:21:14 nlesageSW k3s[3916]: I0214 09:21:14.945600    3916 shared_informer.go:311] Waiting for caches to sync for node config
Feb 14 09:21:17 nlesageSW k3s[3916]: W0214 09:21:17.626582    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:21:17 nlesageSW k3s[3916]: E0214 09:21:17.652354    3916 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"nlesagesw\": Get \"https://127.0.0.1:6444/api/v1/nodes/nlesagesw?resourceVersion=0&timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Feb 14 09:21:22 nlesageSW k3s[3916]: I0214 09:21:22.039421    3916 shared_informer.go:318] Caches are synced for service config
Feb 14 09:21:22 nlesageSW k3s[3916]: I0214 09:21:22.747486    3916 shared_informer.go:318] Caches are synced for node config
Feb 14 09:21:23 nlesageSW k3s[3916]: W0214 09:21:23.304505    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:21:23 nlesageSW k3s[3916]: E0214 09:21:23.309437    3916 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/nlesagesw?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="800ms"
Feb 14 09:21:23 nlesageSW k3s[3916]: I0214 09:21:23.441587    3916 shared_informer.go:318] Caches are synced for endpoint slice config
Feb 14 09:21:27 nlesageSW k3s[3916]: W0214 09:21:27.652651    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:21:27 nlesageSW k3s[3916]: E0214 09:21:27.658954    3916 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"nlesagesw\": Get \"https://127.0.0.1:6444/api/v1/nodes/nlesagesw?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Feb 14 09:21:34 nlesageSW k3s[3916]: W0214 09:21:34.111974    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:21:34 nlesageSW k3s[3916]: E0214 09:21:34.116661    3916 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/nlesagesw?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="1.6s"
Feb 14 09:21:37 nlesageSW k3s[3916]: W0214 09:21:37.660442    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:21:37 nlesageSW k3s[3916]: E0214 09:21:37.664570    3916 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"nlesagesw\": Get \"https://127.0.0.1:6444/api/v1/nodes/nlesagesw?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Feb 14 09:21:45 nlesageSW k3s[3916]: W0214 09:21:45.722588    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:21:45 nlesageSW k3s[3916]: E0214 09:21:45.729010    3916 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/nlesagesw?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="3.2s"
Feb 14 09:21:47 nlesageSW k3s[3916]: W0214 09:21:47.665703    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:21:47 nlesageSW k3s[3916]: E0214 09:21:47.670092    3916 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"nlesagesw\": Get \"https://127.0.0.1:6444/api/v1/nodes/nlesagesw?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Feb 14 09:21:48 nlesageSW k3s[3916]: time="2024-02-14T09:21:48Z" level=info msg="Failed to set annotations and labels on node nlesagesw: Operation cannot be fulfilled on nodes \"nlesagesw\": the object has been modified; please apply your changes to the latest version and try again"
Feb 14 09:22:03 nlesageSW k3s[3916]: time="2024-02-14T09:22:03Z" level=info msg="Annotations and labels have been set successfully on node: nlesagesw"
Feb 14 09:22:03 nlesageSW k3s[3916]: time="2024-02-14T09:22:03Z" level=info msg="Starting flannel with backend vxlan"
Feb 14 09:22:07 nlesageSW k3s[3916]: W0214 09:22:07.022694    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:22:07 nlesageSW k3s[3916]: E0214 09:22:07.027116    3916 kubelet_node_status.go:540] "Error updating node status, will retry" err="failed to patch status \"{\\\"status\\\":{\\\"$setElementOrder/conditions\\\":[{\\\"type\\\":\\\"MemoryPressure\\\"},{\\\"type\\\":\\\"DiskPressure\\\"},{\\\"type\\\":\\\"PIDPressure\\\"},{\\\"type\\\":\\\"Ready\\\"}],\\\"conditions\\\":[{\\\"lastHeartbeatTime\\\":\\\"2024-02-14T09:21:57Z\\\",\\\"type\\\":\\\"MemoryPressure\\\"},{\\\"lastHeartbeatTime\\\":\\\"2024-02-14T09:21:57Z\\\",\\\"type\\\":\\\"DiskPressure\\\"},{\\\"lastHeartbeatTime\\\":\\\"2024-02-14T09:21:57Z\\\",\\\"type\\\":\\\"PIDPressure\\\"},{\\\"lastHeartbeatTime\\\":\\\"2024-02-14T09:21:57Z\\\",\\\"lastTransitionTime\\\":\\\"2024-02-14T09:21:57Z\\\",\\\"message\\\":\\\"kubelet is posting ready status. AppArmor enabled\\\",\\\"reason\\\":\\\"KubeletReady\\\",\\\"status\\\":\\\"True\\\",\\\"type\\\":\\\"Ready\\\"}]}}\" for node \"nlesagesw\": Patch \"https://127.0.0.1:6444/api/v1/nodes/nlesagesw/status?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Feb 14 09:22:07 nlesageSW k3s[3916]: E0214 09:22:07.027203    3916 kubelet_node_status.go:527] "Unable to update node status" err="update node status exceeds retry count"
Feb 14 09:22:07 nlesageSW k3s[3916]: I0214 09:22:07.033633    3916 kubelet_node_status.go:493] "Fast updating node status as it just became ready"
Feb 14 09:22:09 nlesageSW k3s[3916]: W0214 09:22:09.815209    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:22:09 nlesageSW k3s[3916]: E0214 09:22:09.819773    3916 controller.go:146] "Failed to ensure lease exists, will retry" err="Post \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="6.4s"
Feb 14 09:22:17 nlesageSW k3s[3916]: W0214 09:22:17.037563    3916 transport.go:301] Unable to cancel request for *otelhttp.Transport
Feb 14 09:22:17 nlesageSW k3s[3916]: E0214 09:22:17.042657    3916 kubelet_node_status.go:497] "Error updating node status, will retry with syncNodeStatus" err="failed to patch status \"{\\\"status\\\":{\\\"$setElementOrder/conditions\\\":[{\\\"type\\\":\\\"MemoryPressure\\\"},{\\\"type\\\":\\\"DiskPressure\\\"},{\\\"type\\\":\\\"PIDPressure\\\"},{\\\"type\\\":\\\"Ready\\\"}],\\\"conditions\\\":[{\\\"lastHeartbeatTime\\\":\\\"2024-02-14T09:22:07Z\\\",\\\"type\\\":\\\"MemoryPressure\\\"},{\\\"lastHeartbeatTime\\\":\\\"2024-02-14T09:22:07Z\\\",\\\"type\\\":\\\"DiskPressure\\\"},{\\\"lastHeartbeatTime\\\":\\\"2024-02-14T09:22:07Z\\\",\\\"type\\\":\\\"PIDPressure\\\"},{\\\"lastHeartbeatTime\\\":\\\"2024-02-14T09:22:07Z\\\",\\\"lastTransitionTime\\\":\\\"2024-02-14T09:22:07Z\\\",\\\"message\\\":\\\"kubelet is posting ready status. AppArmor enabled\\\",\\\"reason\\\":\\\"KubeletReady\\\",\\\"status\\\":\\\"True\\\",\\\"type\\\":\\\"Ready\\\"}]}}\" for node \"nlesagesw\": Patch \"https://127.0.0.1:6444/api/v1/nodes/nlesagesw/status?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Feb 14 09:22:18 nlesageSW k3s[3916]: time="2024-02-14T09:22:18Z" level=info msg="Tunnel authorizer set Kubelet Port 10250"
Feb 14 09:22:26 nlesageSW k3s[3916]: time="2024-02-14T09:22:26Z" level=info msg="Flannel found PodCIDR assigned for node nlesagesw"
Feb 14 09:22:26 nlesageSW k3s[3916]: time="2024-02-14T09:22:26Z" level=info msg="The interface enp0s3 with ipv4 address 10.0.2.15 will be used by flannel"
Feb 14 09:22:27 nlesageSW k3s[3916]: I0214 09:22:27.046329    3916 kube.go:145] Waiting 10m0s for node controller to sync
Feb 14 09:22:27 nlesageSW k3s[3916]: I0214 09:22:27.050450    3916 kube.go:489] Starting kube subnet manager
Feb 14 09:22:31 nlesageSW k3s[3916]: I0214 09:22:31.031407    3916 kuberuntime_manager.go:1528] "Updating runtime config through cri with podcidr" CIDR="10.42.1.0/24"
Feb 14 09:22:31 nlesageSW k3s[3916]: I0214 09:22:31.039108    3916 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.42.1.0/24"
Feb 14 09:22:31 nlesageSW k3s[3916]: I0214 09:22:31.716547    3916 kube.go:510] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.0.0/24]
Feb 14 09:22:32 nlesageSW k3s[3916]: I0214 09:22:32.053528    3916 kube.go:152] Node controller sync successful
Feb 14 09:22:32 nlesageSW k3s[3916]: I0214 09:22:32.058075    3916 vxlan.go:141] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false
Feb 14 09:22:43 nlesageSW k3s[3916]: time="2024-02-14T09:22:43Z" level=info msg="Starting network policy controller version v2.0.0-20230925161250-364f994b140b, built on 2024-02-06T01:58:54Z, go1.20.13"
Feb 14 09:22:43 nlesageSW k3s[3916]: time="2024-02-14T09:22:43Z" level=info msg="k3s agent is up and running"
Feb 14 09:22:43 nlesageSW k3s[3916]: I0214 09:22:43.174761    3916 network_policy_controller.go:164] Starting network policy controller
Feb 14 09:22:43 nlesageSW systemd[1]: Started k3s-agent.service - Lightweight Kubernetes.
Feb 14 09:22:44 nlesageSW k3s[3916]: I0214 09:22:44.349602    3916 network_policy_controller.go:176] Starting network policy controller full sync goroutine
Feb 14 09:22:44 nlesageSW k3s[3916]: I0214 09:22:44.622432    3916 kube.go:510] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.1.0/24]
Feb 14 09:22:45 nlesageSW k3s[3916]: time="2024-02-14T09:22:45Z" level=info msg="Wrote flannel subnet file to /run/flannel/subnet.env"
Feb 14 09:22:45 nlesageSW k3s[3916]: time="2024-02-14T09:22:45Z" level=info msg="Running flannel backend."
Feb 14 09:22:45 nlesageSW k3s[3916]: I0214 09:22:45.344149    3916 vxlan_network.go:65] watching for new subnet leases
Feb 14 09:22:45 nlesageSW k3s[3916]: I0214 09:22:45.345150    3916 subnet.go:159] Batch elem [0] is { lease.Event{Type:0, Lease:lease.Lease{EnableIPv4:true, EnableIPv6:false, Subnet:ip.IP4Net{IP:0xa2a0000, PrefixLen:0x18}, IPv6Subnet:ip.IP6Net{IP:(*ip.IP6)(nil), PrefixLen:0x0}, Attrs:lease.LeaseAttrs{PublicIP:0xa00020f, PublicIPv6:(*ip.IP6)(nil), BackendType:"vxlan", BackendData:json.RawMessage{0x7b, 0x22, 0x56, 0x4e, 0x49, 0x22, 0x3a, 0x31, 0x2c, 0x22, 0x56, 0x74, 0x65, 0x70, 0x4d, 0x41, 0x43, 0x22, 0x3a, 0x22, 0x66, 0x65, 0x3a, 0x31, 0x34, 0x3a, 0x32, 0x61, 0x3a, 0x66, 0x35, 0x3a, 0x35, 0x64, 0x3a, 0x31, 0x37, 0x22, 0x7d}, BackendV6Data:json.RawMessage(nil)}, Expiration:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Asof:0}} }
Feb 14 09:22:45 nlesageSW k3s[3916]: I0214 09:22:45.369112    3916 iptables.go:290] generated 7 rules
Feb 14 09:22:45 nlesageSW k3s[3916]: I0214 09:22:45.395809    3916 iptables.go:290] generated 3 rules
Feb 14 09:22:46 nlesageSW k3s[3916]: I0214 09:22:46.269403    3916 iptables.go:283] bootstrap done
Feb 14 09:22:46 nlesageSW k3s[3916]: I0214 09:22:46.419286    3916 iptables.go:283] bootstrap done
Feb 14 09:23:02 nlesageSW k3s[3916]: I0214 09:23:02.830115    3916 topology_manager.go:215] "Topology Admit Handler" podUID="a2f4aa25-d8d2-4964-9841-c2e6ad726447" podNamespace="kube-system" podName="svclb-traefik-4708fc55-499f9"
Feb 14 09:23:17 nlesageSW k3s[3916]: E0214 09:23:17.794381    3916 cadvisor_stats_provider.go:444] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-poda2f4aa25_d8d2_4964_9841_c2e6ad726447.slice/cri-containerd-1368a50c02b14903dd13eb40ef096741d4ab3eec3b7580c9556e8664be13079b.scope\": RecentStats: unable to find data in memory cache]"
